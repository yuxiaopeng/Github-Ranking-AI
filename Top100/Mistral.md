[Github Ranking](../README.md)
==========

## Top 100 Stars in Mistral

| Ranking | Project Name | Stars | Forks | Language | Open Issues | Description | Last Commit |
| ------- | ------------ | ----- | ----- | -------- | ----------- | ----------- | ----------- |
| 1 | [ollama](https://github.com/ollama/ollama) | 134293 | 11109 | Go | 1484 | Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 3, and other large language models. | 2025-03-22T03:21:38Z |
| 2 | [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) | 45007 | 5509 | Python | 405 | Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024) | 2025-03-21T02:56:48Z |
| 3 | [unsloth](https://github.com/unslothai/unsloth) | 35510 | 2730 | Python | 908 | Finetune Llama 3.3, DeepSeek-R1, Gemma 3 & Reasoning LLMs 2x faster with 70% less memory! ü¶• | 2025-03-22T01:02:15Z |
| 4 | [LocalAI](https://github.com/mudler/LocalAI) | 31165 | 2360 | Go | 415 | :robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI,  running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P inference | 2025-03-22T22:18:56Z |
| 5 | [khoj](https://github.com/khoj-ai/khoj) | 26809 | 1474 | Python | 67 | Your AI second brain. Self-hostable. Get answers from the web or your docs. Build custom agents, schedule automations, do deep research. Turn any online or local LLM into your personal, autonomous AI (gpt, claude, gemini, llama, qwen, mistral). Get started - free. | 2025-03-20T08:37:22Z |
| 6 | [LibreChat](https://github.com/danny-avila/LibreChat) | 23528 | 3934 | TypeScript | 139 | Enhanced ChatGPT Clone: Features Agents, DeepSeek, Anthropic, AWS, OpenAI, Assistants API, Azure, Groq, o1, GPT-4o, Mistral, OpenRouter, Vertex AI, Gemini, Artifacts, AI model switching, message search, Code Interpreter, langchain, DALL-E-3, OpenAPI Actions, Functions, Secure Multi-User Auth, Presets, open-source for self-hosting. Active project. | 2025-03-23T02:07:53Z |
| 7 | [ludwig](https://github.com/ludwig-ai/ludwig) | 11388 | 1204 | Python | 38 | Low-code framework for building custom LLMs, neural networks, and other AI models | 2025-03-03T20:40:07Z |
| 8 | [OpenLLM](https://github.com/bentoml/OpenLLM) | 11011 | 704 | Python | 0 | Run any open-source LLMs, such as DeepSeek and Llama, as OpenAI compatible API endpoint in the cloud. | 2025-03-18T05:09:35Z |
| 9 | [mistral-inference](https://github.com/mistralai/mistral-inference) | 10120 | 907 | Jupyter Notebook | 121 | Official inference library for Mistral models | 2025-03-20T15:03:08Z |
| 10 | [ipex-llm](https://github.com/intel/ipex-llm) | 7603 | 1332 | Python | 1099 | Accelerate local LLM inference and finetuning (LLaMA, Mistral, ChatGLM, Qwen, DeepSeek, Mixtral, Gemma, Phi, MiniCPM, Qwen-VL, MiniCPM-V, etc.) on Intel XPU (e.g., local PC with iGPU and NPU, discrete GPU such as Arc, Flex and Max); seamlessly integrate with llama.cpp, Ollama, HuggingFace, LangChain, LlamaIndex, vLLM, DeepSpeed, Axolotl, etc. | 2025-03-21T07:52:22Z |
| 11 | [inference](https://github.com/xorbitsai/inference) | 7166 | 588 | Python | 166 | Replace OpenAI GPT with another LLM in your app by changing a single line of code. Xinference gives you the freedom to use any LLM you need. With Xinference, you're empowered to run inference with any open-source language models, speech recognition models, and multimodal models, whether in the cloud, on-premises, or even on your laptop. | 2025-03-21T07:17:53Z |
| 12 | [ms-swift](https://github.com/modelscope/ms-swift) | 6471 | 555 | Python | 466 | Use PEFT or Full-parameter to finetune 450+ LLMs (Qwen2.5, InternLM3, GLM4, Llama3.3, Mistral, Yi1.5, Baichuan2, DeepSeek-R1, ...) and 150+ MLLMs (Qwen2.5-VL, Qwen2-Audio, Llama3.2-Vision, Llava, InternVL2.5, MiniCPM-V-2.6, GLM4v, Xcomposer2.5, Yi-VL, DeepSeek-VL2, Phi3.5-Vision, GOT-OCR2, ...). | 2025-03-22T15:04:35Z |
| 13 | [Firefly](https://github.com/yangjianxin1/Firefly) | 6270 | 566 | Python | 204 | Firefly: Â§ßÊ®°ÂûãËÆ≠ÁªÉÂ∑•ÂÖ∑ÔºåÊîØÊåÅËÆ≠ÁªÉQwen2.5„ÄÅQwen2„ÄÅYi1.5„ÄÅPhi-3„ÄÅLlama3„ÄÅGemma„ÄÅMiniCPM„ÄÅYi„ÄÅDeepseek„ÄÅOrion„ÄÅXverse„ÄÅMixtral-8x7B„ÄÅZephyr„ÄÅMistral„ÄÅBaichuan2„ÄÅLlma2„ÄÅLlama„ÄÅQwen„ÄÅBaichuan„ÄÅChatGLM2„ÄÅInternLM„ÄÅZiya2„ÄÅVicuna„ÄÅBloomÁ≠âÂ§ßÊ®°Âûã | 2024-10-24T02:27:42Z |
| 14 | [big-AGI](https://github.com/enricoros/big-AGI) | 6243 | 1436 | TypeScript | 232 | AI suite powered by state-of-the-art models and providing advanced AI/AGI functions. It features AI personas, AGI functions, multi-model chats, text-to-image, voice, response streaming, code highlighting and execution, PDF import, presets for developers, much more. Deploy on-prem or in the cloud. | 2025-03-21T17:06:11Z |
| 15 | [mistral.rs](https://github.com/EricLBuehler/mistral.rs) | 5281 | 381 | Rust | 105 | Blazingly fast LLM inference. | 2025-03-23T02:31:03Z |
| 16 | [enchanted](https://github.com/gluonfield/enchanted) | 5066 | 322 | Swift | 88 | Enchanted is iOS and macOS app for chatting with private self hosted language models such as Llama2, Mistral or Vicuna using Ollama. | 2025-03-19T20:19:21Z |
| 17 | [opencompass](https://github.com/open-compass/opencompass) | 4995 | 527 | Python | 281 | OpenCompass is an LLM evaluation platform, supporting a wide range of models (Llama3, Mistral, InternLM2,GPT-4,LLaMa2, Qwen,GLM, Claude, etc) over 100+ datasets. | 2025-03-21T12:09:25Z |
| 18 | [Liger-Kernel](https://github.com/linkedin/Liger-Kernel) | 4698 | 284 | Python | 53 | Efficient Triton Kernels for LLM Training | 2025-03-22T02:10:51Z |
| 19 | [awesome-LLM-resourses](https://github.com/WangRongsheng/awesome-LLM-resourses) | 4414 | 455 | None | 0 | üßë‚ÄçüöÄ ÂÖ®‰∏ñÁïåÊúÄÂ•ΩÁöÑLLMËµÑÊñôÊÄªÁªìÔºàÊï∞ÊçÆÂ§ÑÁêÜ„ÄÅÊ®°ÂûãËÆ≠ÁªÉ„ÄÅÊ®°ÂûãÈÉ®ÁΩ≤„ÄÅo1 Ê®°Âûã„ÄÅMCP„ÄÅÂ∞èËØ≠Ë®ÄÊ®°Âûã„ÄÅËßÜËßâËØ≠Ë®ÄÊ®°ÂûãÔºâ \| Summary of the world's best LLM resources.  | 2025-03-22T14:10:04Z |
| 20 | [xtuner](https://github.com/InternLM/xtuner) | 4406 | 332 | Python | 213 | An efficient, flexible and full-featured toolkit for fine-tuning LLM (InternLM2, Llama3, Phi3, Qwen, Mistral, ...) | 2025-03-22T14:27:53Z |
| 21 | [agentops](https://github.com/AgentOps-AI/agentops) | 4082 | 365 | Python | 83 | Python SDK for AI agent monitoring, LLM cost tracking, benchmarking, and more. Integrates with most LLMs and agent frameworks including OpenAI Agents SDK, CrewAI, Langchain, Autogen, AG2, and CamelAI | 2025-03-23T03:08:04Z |
| 22 | [chinese-llm-benchmark](https://github.com/jeinlee1991/chinese-llm-benchmark) | 3819 | 166 | None | 28 | ÁõÆÂâçÂ∑≤ÂõäÊã¨203‰∏™Â§ßÊ®°ÂûãÔºåË¶ÜÁõñchatgpt„ÄÅgpt-4o„ÄÅo3-mini„ÄÅË∞∑Ê≠ågemini„ÄÅClaude3.5„ÄÅÊô∫Ë∞±GLM-Zero„ÄÅÊñáÂøÉ‰∏ÄË®Ä„ÄÅqwen-max„ÄÅÁôæÂ∑ù„ÄÅËÆØÈ£ûÊòüÁÅ´„ÄÅÂïÜÊ±§senseChat„ÄÅminimaxÁ≠âÂïÜÁî®Ê®°ÂûãÔºå ‰ª•ÂèäDeepSeek-R1„ÄÅqwq-32b„ÄÅdeepseek-v3„ÄÅqwen2.5„ÄÅllama3.3„ÄÅphi-4„ÄÅglm4„ÄÅgemma3„ÄÅmistral„ÄÅ‰π¶ÁîüinternLM2.5Á≠âÂºÄÊ∫êÂ§ßÊ®°Âûã„ÄÇ‰∏ç‰ªÖÊèê‰æõËÉΩÂäõËØÑÂàÜÊéíË°åÊ¶úÔºå‰πüÊèê‰æõÊâÄÊúâÊ®°ÂûãÁöÑÂéüÂßãËæìÂá∫ÁªìÊûúÔºÅ | 2025-03-21T08:05:49Z |
| 23 | [mistral-finetune](https://github.com/mistralai/mistral-finetune) | 2892 | 260 | Python | 31 | None | 2024-09-13T09:53:13Z |
| 24 | [AI-System-School](https://github.com/HuaizhengZhang/AI-System-School) | 2827 | 321 | None | 12 | üöÄ Awesome System for Machine Learning ‚ö°Ô∏è AI System Papers and Industry Practice. ‚ö°Ô∏è System for Machine Learning, LLM (Large Language Model), GenAI (Generative AI). üçª OSDI, NSDI, SIGCOMM, SoCC, MLSys, etc. üóÉÔ∏è Llama3, Mistral, etc. üßë‚Äçüíª Video Tutorials.  | 2024-08-14T05:12:47Z |
| 25 | [paperless-ai](https://github.com/clusterzx/paperless-ai) | 2744 | 97 | JavaScript | 9 | An automated document analyzer for Paperless-ngx using OpenAI API, Ollama, Deepseek-r1, Azure and all OpenAI API compatible Services to automatically analyze and tag your documents. | 2025-03-21T19:24:53Z |
| 26 | [xTuring](https://github.com/stochasticai/xTuring) | 2640 | 207 | Python | 10 | Build, customize and control you own LLMs. From data pre-processing to fine-tuning, xTuring provides an easy way to personalize open-source LLMs. Join our discord community: https://discord.gg/TgHXuSJEk6 | 2024-09-23T09:40:48Z |
| 27 | [lsp-ai](https://github.com/SilasMarvin/lsp-ai) | 2613 | 92 | Rust | 24 | LSP-AI is an open-source language server that serves as a backend for AI-powered functionality, designed to assist and empower software engineers, not replace them. | 2025-01-07T22:17:38Z |
| 28 | [secret-llama](https://github.com/abi/secret-llama) | 2602 | 164 | TypeScript | 18 | Fully private LLM chatbot that runs entirely with a browser with no server needed. Supports Mistral and LLama 3. | 2024-06-05T02:04:17Z |
| 29 | [elia](https://github.com/darrenburns/elia) | 2077 | 130 | Python | 12 | A snappy, keyboard-centric terminal user interface for interacting with large language models. Chat with ChatGPT, Claude, Llama 3, Phi 3, Mistral, Gemma and more. | 2024-10-10T19:12:52Z |
| 30 | [OnnxStream](https://github.com/vitoplantamura/OnnxStream) | 1925 | 89 | C++ | 54 | Lightweight inference library for ONNX files, written in C++. It can run Stable Diffusion XL 1.0 on a RPI Zero 2 (or in 298MB of RAM) but also Mistral 7B on desktops and servers. ARM, x86, WASM, RISC-V supported. Accelerated by XNNPACK. | 2025-03-18T05:20:30Z |
| 31 | [maid](https://github.com/Mobile-Artificial-Intelligence/maid) | 1795 | 205 | Dart | 10 | Maid is a cross-platform Flutter app for interfacing with GGUF / llama.cpp models locally, and with Ollama and OpenAI models remotely.  | 2025-03-20T03:09:05Z |
| 32 | [floneum](https://github.com/floneum/floneum) | 1794 | 91 | Rust | 39 | Instant, controllable, local pre-trained AI models in Rust | 2025-03-22T18:52:01Z |
| 33 | [Ollamac](https://github.com/kevinhermawan/Ollamac) | 1741 | 95 | Swift | 35 | Mac app for Ollama | 2025-03-12T22:28:22Z |
| 34 | [dialoqbase](https://github.com/n4ze3m/dialoqbase) | 1740 | 273 | TypeScript | 39 | Create chatbots with ease | 2024-10-15T14:24:20Z |
| 35 | [json_repair](https://github.com/mangiucugna/json_repair) | 1620 | 80 | Python | 0 | A python module to repair invalid JSON from LLMs | 2025-03-19T12:21:14Z |
| 36 | [papersgpt-for-zotero](https://github.com/papersgpt/papersgpt-for-zotero) | 1413 | 46 | JavaScript | 36 | Zotero chat PDF with AI, DeepSeek, GPT 4.5, ChatGPT, Claude, Gemini | 2025-03-13T04:00:46Z |
| 37 | [search2ai](https://github.com/fatwang2/search2ai) | 1258 | 192 | JavaScript | 17 | Help your LLMs online | 2025-02-19T16:26:01Z |
| 38 | [modelfusion](https://github.com/vercel/modelfusion) | 1243 | 89 | TypeScript | 33 | The TypeScript library for building AI applications. | 2024-07-19T15:17:19Z |
| 39 | [aws-genai-llm-chatbot](https://github.com/aws-samples/aws-genai-llm-chatbot) | 1203 | 366 | TypeScript | 21 | A modular and comprehensive solution to deploy a Multi-LLM and Multi-RAG powered chatbot (Amazon Bedrock, Anthropic, HuggingFace, OpenAI, Meta, AI21, Cohere, Mistral) using AWS CDK on AWS | 2025-02-20T15:20:46Z |
| 40 | [nextjs-ollama-llm-ui](https://github.com/jakobhoeg/nextjs-ollama-llm-ui) | 1150 | 278 | TypeScript | 13 | Fully-featured web interface for Ollama LLMs | 2025-02-04T19:07:06Z |
| 41 | [gp.nvim](https://github.com/Robitx/gp.nvim) | 1095 | 93 | Lua | 41 | Gp.nvim (GPT prompt) Neovim AI plugin: ChatGPT sessions & Instructable text/code operations & Speech to text [OpenAI, Ollama, Anthropic, ..] | 2024-09-23T12:32:50Z |
| 42 | [bedrock-claude-chat](https://github.com/aws-samples/bedrock-claude-chat) | 1066 | 392 | TypeScript | 111 | AWS-native chatbot using Bedrock + Claude (+Nova and Mistral) | 2025-03-21T17:46:28Z |
| 43 | [poe-api-wrapper](https://github.com/snowby666/poe-api-wrapper) | 1062 | 137 | Python | 27 | üëæ A Python API wrapper for Poe.com. With this, you will have free access to GPT-4, Claude, Llama, Gemini, Mistral and more! üöÄ | 2025-03-07T20:07:31Z |
| 44 | [LLM-Prompt-Library](https://github.com/abilzerian/LLM-Prompt-Library) | 1043 | 112 | Python | 0 | My personal prompt library for various LLMs + scripts & tools. Suitable for models from Deepseek, OpenAI, Claude, Meta, Mistral, Google, Grok, and others. | 2025-03-18T17:04:23Z |
| 45 | [chatd](https://github.com/BruceMacD/chatd) | 1016 | 69 | JavaScript | 26 | Chat with your documents using local AI | 2024-07-06T01:21:36Z |
| 46 | [BaseAI](https://github.com/LangbaseInc/BaseAI) | 978 | 82 | TypeScript | 4 | BaseAI ‚Äî The Web AI Framework. The easiest way to build serverless autonomous AI agents with memory. Start building local-first, agentic pipes, tools, and memory. Deploy serverless with one command. | 2025-02-25T11:30:28Z |
| 47 | [RisuAI](https://github.com/kwaroran/RisuAI) | 944 | 163 | TypeScript | 59 | Make your own story. User-friendly software for LLM roleplaying | 2025-03-22T12:27:31Z |
| 48 | [graphrag-local-ollama](https://github.com/TheAiSingularity/graphrag-local-ollama) | 936 | 148 | Python | 42 | Local models support for Microsoft's graphrag using ollama (llama3, mistral, gemma2 phi3)- LLM & Embedding extraction | 2024-09-30T02:43:30Z |
| 49 | [ai-dev-gallery](https://github.com/microsoft/ai-dev-gallery) | 917 | 111 | C# | 40 | An open-source project for Windows developers to learn how to add AI with local models and APIs to Windows apps. | 2025-03-21T22:20:48Z |
| 50 | [generative-ai-use-cases-jp](https://github.com/aws-samples/generative-ai-use-cases-jp) | 858 | 203 | TypeScript | 88 | „Åô„Åê„Å´Ê•≠ÂãôÊ¥ªÁî®„Åß„Åç„Çã„Éì„Ç∏„Éç„Çπ„É¶„Éº„Çπ„Ç±„Éº„ÇπÈõÜ‰ªò„Åç„ÅÆÂÆâÂÖ®„Å™ÁîüÊàêAI„Ç¢„Éó„É™ÂÆüË£Ö | 2025-03-21T08:54:43Z |
| 51 | [witsy](https://github.com/nbonamy/witsy) | 791 | 56 | TypeScript | 3 | Witsy: desktop AI assistant | 2025-03-21T22:04:20Z |
| 52 | [MixtralKit](https://github.com/open-compass/MixtralKit) | 767 | 80 | Python | 12 | A toolkit for inference and evaluation of 'mixtral-8x7b-32kseqlen' from Mistral AI | 2023-12-15T19:10:55Z |
| 53 | [fine-tune-mistral](https://github.com/abacaj/fine-tune-mistral) | 709 | 63 | Python | 3 | Fine-tune mistral-7B on 3090s, a100s, h100s | 2023-10-11T17:25:59Z |
| 54 | [mistral-common](https://github.com/mistralai/mistral-common) | 698 | 78 | Python | 17 | None | 2025-03-19T22:27:53Z |
| 55 | [web-llm-chat](https://github.com/mlc-ai/web-llm-chat) | 694 | 114 | TypeScript | 9 | Chat with AI large language models running natively in your browser. Enjoy private, server-free, seamless AI conversations. | 2025-01-29T19:23:34Z |
| 56 | [Hexabot](https://github.com/Hexastack/Hexabot) | 681 | 120 | TypeScript | 118 | Hexabot is an open-source AI chatbot / agent builder. It allows you to create and manage multi-channel and multilingual chatbots / agents with ease.  | 2025-03-22T16:10:20Z |
| 57 | [tt-metal](https://github.com/tenstorrent/tt-metal) | 672 | 120 | C++ | 2131 | :metal: TT-NN operator library, and TT-Metalium low level kernel programming model. | 2025-03-23T03:20:14Z |
| 58 | [ComfyUI-IF_AI_tools](https://github.com/if-ai/ComfyUI-IF_AI_tools) | 615 | 47 | Python | 50 | ComfyUI-IF_AI_tools is a set of custom nodes for ComfyUI that allows you to generate prompts using a local Large Language Model (LLM) via Ollama. This tool enables you to enhance your image generation workflow by leveraging the power of language models. | 2025-03-09T09:11:32Z |
| 59 | [llm-finetuning](https://github.com/modal-labs/llm-finetuning) | 573 | 89 | Python | 3 | Guide for fine-tuning Llama/Mistral/CodeLlama models and more | 2024-08-28T10:44:08Z |
| 60 | [mistral](https://github.com/stanford-crfm/mistral) | 569 | 52 | Python | 18 | Mistral: A strong, northwesterly wind: Framework for transparent and accessible large-scale language model training, built with Hugging Face ü§ó  Transformers. | 2023-11-10T02:55:18Z |
| 61 | [Owl](https://github.com/OwlAIProject/Owl) | 568 | 56 | Python | 6 | A personal wearable AI that runs locally | 2024-03-17T06:37:26Z |
| 62 | [client-python](https://github.com/mistralai/client-python) | 564 | 119 | Python | 13 | Python client library for Mistral AI platform | 2025-03-21T09:33:25Z |
| 63 | [parrot.nvim](https://github.com/frankroeder/parrot.nvim) | 546 | 35 | Lua | 3 | parrot.nvim ü¶ú - the plugin that brings stochastic parrots to Neovim. | 2025-03-18T11:57:54Z |
| 64 | [BambooAI](https://github.com/pgalko/BambooAI) | 540 | 54 | Python | 11 | A Python library powered by Language Models (LLMs) for conversational data discovery and analysis. | 2025-03-02T07:52:21Z |
| 65 | [ai-commits-intellij-plugin](https://github.com/Blarc/ai-commits-intellij-plugin) | 516 | 41 | Kotlin | 23 | AI Commits for IntelliJ based IDEs/Android Studio. | 2025-03-21T05:09:42Z |
| 66 | [llmcord](https://github.com/jakobdylanc/llmcord) | 503 | 98 | Python | 2 | Make Discord your LLM frontend ‚óè Supports any OpenAI compatible API (Ollama, LM Studio, vLLM, OpenRouter, xAI, Mistral, Groq and more) | 2025-03-21T19:37:29Z |
| 67 | [rag-chatbot](https://github.com/datvodinh/rag-chatbot) | 488 | 74 | Python | 6 |  Chat with multiple PDFs locally | 2024-10-11T04:30:01Z |
| 68 | [helix](https://github.com/helixml/helix) | 473 | 47 | Go | 124 | üß¨ Helix is a private GenAI stack for building AI applications with declarative pipelines, knowledge (RAG), API bindings, and first-class testing. | 2025-03-22T19:10:30Z |
| 69 | [embedJs](https://github.com/llm-tools/embedJs) | 470 | 52 | TypeScript | 25 | A NodeJS RAG framework to easily work with LLMs and embeddings | 2025-02-14T10:53:44Z |
| 70 | [ollama-voice-mac](https://github.com/apeatling/ollama-voice-mac) | 467 | 54 | Python | 8 | Mac compatible Ollama Voice | 2024-03-26T14:49:04Z |
| 71 | [aikit](https://github.com/sozercan/aikit) | 436 | 36 | Go | 20 | üèóÔ∏è Fine-tune, build, and deploy open-source LLMs easily! | 2025-03-17T03:13:08Z |
| 72 | [mlx-llm](https://github.com/riccardomusmeci/mlx-llm) | 430 | 30 | Python | 0 | Large Language Models (LLMs) applications and tools running on Apple Silicon in real-time with Apple MLX. | 2025-01-29T07:13:07Z |
| 73 | [obsidian-bmo-chatbot](https://github.com/longy2k/obsidian-bmo-chatbot) | 430 | 59 | TypeScript | 45 | Generate and brainstorm ideas while creating your notes using Large Language Models (LLMs) from Ollama, LM Studio, Anthropic, Google Gemini, Mistral AI, OpenAI, and more for Obsidian. | 2024-09-12T04:07:29Z |
| 74 | [LESS](https://github.com/princeton-nlp/LESS) | 421 | 40 | Jupyter Notebook | 15 | [ICML 2024] LESS: Selecting Influential Data for Targeted Instruction Tuning | 2024-10-20T03:11:58Z |
| 75 | [bolna](https://github.com/voxos-ai/bolna) | 413 | 112 | Python | 28 | End-to-end platform for building voice first multimodal agents | 2024-10-28T05:40:38Z |
| 76 | [xllm](https://github.com/BobaZooba/xllm) | 400 | 21 | Python | 6 | ü¶ñ X‚ÄîLLM: Cutting Edge & Easy LLM Finetuning | 2024-01-17T16:43:39Z |
| 77 | [DevoxxGenieIDEAPlugin](https://github.com/devoxx/DevoxxGenieIDEAPlugin) | 394 | 47 | Java | 39 | DevoxxGenie is a plugin for IntelliJ IDEA that uses local LLM's (Ollama, LMStudio, GPT4All, Jan and Llama.cpp) and Cloud based LLMs to help review, test, explain your project code. | 2025-03-22T17:28:47Z |
| 78 | [fltr](https://github.com/moritztng/fltr) | 380 | 8 | Rust | 1 | Like grep but for natural language questions. Based on Mistral 7B or Mixtral 8x7B. | 2024-03-13T11:39:01Z |
| 79 | [GPTPortal](https://github.com/Zaki-1052/GPTPortal) | 363 | 65 | JavaScript | 2 | A feature-rich portal to chat with GPT-4, Claude, Gemini, Mistral, & OpenAI Assistant APIs via a lightweight Node.js web app; supports customizable multimodality for voice, images, & files. | 2025-03-07T19:37:35Z |
| 80 | [edgen](https://github.com/edgenai/edgen) | 356 | 16 | Rust | 23 | ‚ö°  Edgen: Local, private GenAI server alternative to OpenAI. No GPU required. Run AI models locally: LLMs (Llama2, Mistral, Mixtral...), Speech-to-text (whisper) and many others. | 2024-05-23T14:21:38Z |
| 81 | [NeuralFlow](https://github.com/valine/NeuralFlow) | 344 | 15 | Python | 4 | Visualize the intermediate output of Mistral 7B | 2025-01-22T11:25:17Z |
| 82 | [ai_automation_suggester](https://github.com/ITSpecialist111/ai_automation_suggester) | 339 | 12 | Python | 4 | This custom Home Assistant integration automatically scans your entities, detects new devices, and uses AI (via cloud and local APIs) to suggest tailored automations. It supports multiple AI providers, including OpenAI, Anthropic, Google, Groq, LocalAI, Mistral and Ollama. The integration provides automation suggestions via HASS notifications | 2025-03-09T20:09:18Z |
| 83 | [KVQuant](https://github.com/SqueezeAILab/KVQuant) | 336 | 30 | Python | 14 | [NeurIPS 2024] KVQuant: Towards 10 Million Context Length LLM Inference with KV Cache Quantization | 2024-08-13T11:19:28Z |
| 84 | [LLaMa2lang](https://github.com/AI-Commandos/LLaMa2lang) | 300 | 34 | Python | 0 | Convenience scripts to finetune (chat-)LLaMa3 and other models for any language | 2024-06-17T14:00:13Z |
| 85 | [mistral](https://github.com/openstack/mistral) | 291 | 118 | Python | 0 | Workflow Service for OpenStack. Mirror of code maintained at opendev.org. | 2025-03-18T23:37:58Z |
| 86 | [airunner](https://github.com/Capsize-Games/airunner) | 284 | 23 | Python | 28 | Stable Diffusion and LLMs offline on your own hardware | 2025-03-23T02:58:42Z |
| 87 | [OllamaKit](https://github.com/kevinhermawan/OllamaKit) | 282 | 29 | Swift | 5 | Ollama client for Swift | 2025-03-09T22:20:34Z |
| 88 | [nanodl](https://github.com/HMUNACHI/nanodl) | 282 | 10 | Python | 2 | A Jax-based library for designing and training transformer models from scratch. | 2024-08-28T21:24:22Z |
| 89 | [simple-openai](https://github.com/sashirestela/simple-openai) | 277 | 30 | Java | 5 | A Java library to use the OpenAI Api in the simplest possible way. | 2025-03-22T20:52:57Z |
| 90 | [yalm](https://github.com/andrewkchan/yalm) | 273 | 27 | C++ | 1 | Yet Another Language Model: LLM inference in C++/CUDA, no libraries except for I/O | 2025-01-15T07:22:42Z |
| 91 | [llm-mistral-invoice-cpu](https://github.com/katanaml/llm-mistral-invoice-cpu) | 264 | 63 | Python | 0 | Data extraction with LLM on CPU | 2024-03-26T05:44:59Z |
| 92 | [Heat](https://github.com/nathanborror/Heat) | 258 | 17 | Swift | 4 | An LLM agnostic desktop and mobile client. | 2025-03-21T16:30:16Z |
| 93 | [unsaged](https://github.com/jorge-menjivar/unsaged) | 255 | 78 | TypeScript | 15 | Open source chat kit engineered for seamless interaction with AI models. | 2025-02-25T18:02:25Z |
| 94 | [aicommit2](https://github.com/tak-bro/aicommit2) | 253 | 20 | TypeScript | 7 | A Reactive CLI that generates git commit messages with Ollama, ChatGPT, Gemini, Claude, Mistral and other AI | 2025-03-18T02:12:34Z |
| 95 | [inferflow](https://github.com/inferflow/inferflow) | 238 | 25 | C++ | 8 | Inferflow is an efficient and highly configurable inference engine for large language models (LLMs). | 2024-03-15T06:52:33Z |
| 96 | [ai-playground](https://github.com/rokbenko/ai-playground) | 234 | 52 | Python | 0 | Code from tutorials presented on the "Code AI with Rok" YouTube channel | 2025-03-18T17:22:38Z |
| 97 | [companion-vscode](https://github.com/quack-ai/companion-vscode) | 231 | 12 | TypeScript | 3 | VSCode extension of Quack Companion üíª Turn your team insights into a portable plug-and-play context for code generation. Alternative to GitHub Copilot powered by OSS LLMs (Mistral, Gemma, etc.), served with Ollama. | 2024-10-01T04:06:14Z |
| 98 | [TPU-Alignment](https://github.com/Locutusque/TPU-Alignment) | 230 | 25 | Jupyter Notebook | 0 | Fully fine-tune large models like Mistral, Llama-2-13B, or Qwen-14B completely for free | 2024-10-31T20:34:59Z |
| 99 | [ProX](https://github.com/GAIR-NLP/ProX) | 229 | 18 | Python | 2 | Offical Repo for "Programming Every Example: Lifting Pre-training Data Quality Like Experts at Scale" | 2025-02-16T07:59:43Z |
| 100 | [ollama-ai](https://github.com/gbaptista/ollama-ai) | 227 | 8 | Ruby | 0 | A Ruby gem for interacting with Ollama's API that allows you to run open source AI LLMs (Large Language Models) locally. | 2024-07-21T11:13:36Z |

