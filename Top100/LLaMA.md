[Github Ranking](../README.md)
==========

## Top 100 Stars in LLaMA

| Ranking | Project Name | Stars | Forks | Language | Open Issues | Description | Last Commit |
| ------- | ------------ | ----- | ----- | -------- | ----------- | ----------- | ----------- |
| 1 | [ollama](https://github.com/ollama/ollama) | 140598 | 11754 | Go | 1550 | Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 3, Mistral Small 3.1 and other large language models. | 2025-05-15T23:35:59Z |
| 2 | [llama.cpp](https://github.com/ggml-org/llama.cpp) | 80302 | 11773 | C++ | 328 | LLM inference in C/C++ | 2025-05-15T23:12:16Z |
| 3 | [llama](https://github.com/meta-llama/llama) | 58241 | 9768 | Python | 432 | Inference code for Llama models | 2025-01-26T21:42:26Z |
| 4 | [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) | 48978 | 5967 | Python | 462 | Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024) | 2025-05-15T02:54:36Z |
| 5 | [vllm](https://github.com/vllm-project/vllm) | 47409 | 7428 | Python | 1831 | A high-throughput and memory-efficient inference and serving engine for LLMs | 2025-05-16T02:30:17Z |
| 6 | [llama_index](https://github.com/run-llama/llama_index) | 41662 | 5940 | Python | 263 | LlamaIndex is the leading framework for building LLM-powered agents over your data. | 2025-05-15T20:02:58Z |
| 7 | [unsloth](https://github.com/unslothai/unsloth) | 38737 | 3035 | Python | 930 | Finetune Qwen3, Llama 4, TTS, DeepSeek-R1 & Gemma 3 LLMs 2x faster with 70% less memory! ğŸ¦¥ | 2025-05-15T22:15:53Z |
| 8 | [quivr](https://github.com/QuivrHQ/quivr) | 37844 | 3638 | Python | 5 | Opiniated RAG for integrating GenAI in your apps ğŸ§    Focus on your product rather than the RAG. Easy integration in existing products with customisation!  Any LLM: GPT4, Groq, Llama. Any Vectorstore: PGVector, Faiss. Any Files. Anyway you want.  | 2025-05-15T07:49:42Z |
| 9 | [Langchain-Chatchat](https://github.com/chatchat-space/Langchain-Chatchat) | 35024 | 5882 | TypeScript | 188 | Langchain-Chatchatï¼ˆåŸLangchain-ChatGLMï¼‰åŸºäº Langchain ä¸ ChatGLM, Qwen ä¸ Llama ç­‰è¯­è¨€æ¨¡å‹çš„ RAG ä¸ Agent åº”ç”¨ \| Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM, Qwen and Llama) RAG and Agent app with langchain  | 2025-03-25T15:45:51Z |
| 10 | [aider](https://github.com/Aider-AI/aider) | 32988 | 2994 | Python | 800 | aider is AI pair programming in your terminal | 2025-05-13T20:45:06Z |
| 11 | [LocalAI](https://github.com/mudler/LocalAI) | 32604 | 2484 | Go | 442 | :robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI,  running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more models architectures. Features: Generate Text, Audio, Video, Images, Voice Cloning, Distributed, P2P inference | 2025-05-15T21:17:11Z |
| 12 | [khoj](https://github.com/khoj-ai/khoj) | 30052 | 1672 | Python | 68 | Your AI second brain. Self-hostable. Get answers from the web or your docs. Build custom agents, schedule automations, do deep research. Turn any online or local LLM into your personal, autonomous AI (gpt, claude, gemini, llama, qwen, mistral). Get started - free. | 2025-05-13T19:05:09Z |
| 13 | [llama3](https://github.com/meta-llama/llama3) | 28699 | 3376 | Python | 171 | The official Meta Llama 3 GitHub site | 2025-01-26T21:39:06Z |
| 14 | [LLaVA](https://github.com/haotian-liu/LLaVA) | 22524 | 2480 | Python | 1070 | [NeurIPS'23 Oral] Visual Instruction Tuning (LLaVA) built towards GPT-4V level capabilities and beyond. | 2024-08-12T09:52:38Z |
| 15 | [llamafile](https://github.com/Mozilla-Ocho/llamafile) | 22403 | 1178 | C++ | 146 | Distribute and run LLMs with a single file. | 2025-05-14T22:23:40Z |
| 16 | [fish-speech](https://github.com/fishaudio/fish-speech) | 21095 | 1688 | Python | 31 | SOTA Open Source TTS | 2025-04-12T14:01:16Z |
| 17 | [Awesome-Chinese-LLM](https://github.com/HqWu-HITCS/Awesome-Chinese-LLM) | 20004 | 1926 | None | 5 | æ•´ç†å¼€æºçš„ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹ï¼Œä»¥è§„æ¨¡è¾ƒå°ã€å¯ç§æœ‰åŒ–éƒ¨ç½²ã€è®­ç»ƒæˆæœ¬è¾ƒä½çš„æ¨¡å‹ä¸ºä¸»ï¼ŒåŒ…æ‹¬åº•åº§æ¨¡å‹ï¼Œå‚ç›´é¢†åŸŸå¾®è°ƒåŠåº”ç”¨ï¼Œæ•°æ®é›†ä¸æ•™ç¨‹ç­‰ã€‚ | 2025-04-08T08:13:03Z |
| 18 | [alpaca-lora](https://github.com/tloen/alpaca-lora) | 18899 | 2227 | Jupyter Notebook | 333 | Instruct-tune LLaMA on consumer hardware | 2024-07-29T13:37:49Z |
| 19 | [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) | 18835 | 1892 | Python | 1 | ä¸­æ–‡LLaMA&Alpacaå¤§è¯­è¨€æ¨¡å‹+æœ¬åœ°CPU/GPUè®­ç»ƒéƒ¨ç½² (Chinese LLaMA & Alpaca LLMs) | 2024-04-30T04:28:38Z |
| 20 | [llama2.c](https://github.com/karpathy/llama2.c) | 18385 | 2250 | C | 124 | Inference Llama 2 in one file of pure C | 2024-08-06T09:44:40Z |
| 21 | [llama-cookbook](https://github.com/meta-llama/llama-cookbook) | 17306 | 2476 | Jupyter Notebook | 17 | Welcome to the Llama Cookbook! This is your go to guide for Building with Llama: Getting started with Inference, Fine-Tuning, RAG. We also show you how to solve end to end problems using Llama model family and using them on various provider services   | 2025-05-14T16:44:20Z |
| 22 | [repomix](https://github.com/yamadashy/repomix) | 15896 | 688 | TypeScript | 82 | ğŸ“¦ Repomix is a powerful tool that packs your entire repository into a single, AI-friendly file. Perfect for when you need to feed your codebase to Large Language Models (LLMs) or other AI tools like Claude, ChatGPT, DeepSeek, Perplexity, Gemini, Gemma, Llama, Grok, and more. | 2025-05-13T14:00:39Z |
| 23 | [ChuanhuChatGPT](https://github.com/GaiZhenbiao/ChuanhuChatGPT) | 15423 | 2282 | Python | 122 | GUI for ChatGPT API and many LLMs. Supports agents, file-based QA, GPT finetuning and query with web search. All with a neat UI. | 2025-03-13T09:36:38Z |
| 24 | [llama3-from-scratch](https://github.com/naklecha/llama3-from-scratch) | 14940 | 1264 | Jupyter Notebook | 13 | llama3 implementation one matrix multiplication at a time | 2024-05-23T14:34:05Z |
| 25 | [Llama-Chinese](https://github.com/LlamaFamily/Llama-Chinese) | 14584 | 1306 | Python | 196 | Llamaä¸­æ–‡ç¤¾åŒºï¼Œå®æ—¶æ±‡æ€»æœ€æ–°Llamaå­¦ä¹ èµ„æ–™ï¼Œæ„å»ºæœ€å¥½çš„ä¸­æ–‡Llamaå¤§æ¨¡å‹å¼€æºç”Ÿæ€ï¼Œå®Œå…¨å¼€æºå¯å•†ç”¨ | 2025-04-06T09:16:55Z |
| 26 | [sglang](https://github.com/sgl-project/sglang) | 14374 | 1762 | Python | 504 | SGLang is a fast serving framework for large language models and vision language models. | 2025-05-16T00:46:43Z |
| 27 | [dalai](https://github.com/cocktailpeanut/dalai) | 13081 | 1397 | CSS | 292 | The simplest way to run LLaMA on your local machine | 2024-06-18T20:29:46Z |
| 28 | [mastra](https://github.com/mastra-ai/mastra) | 13008 | 717 | TypeScript | 74 | The TypeScript AI agent framework. âš¡ Assistants, RAG, observability. Supports any LLM: GPT-4, Claude, Gemini, Llama. | 2025-05-16T00:22:23Z |
| 29 | [PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP) | 12587 | 3027 | Python | 166 | Easy-to-use and powerful LLM and SLM library with awesome model zoo. | 2025-05-15T07:41:50Z |
| 30 | [h2ogpt](https://github.com/h2oai/h2ogpt) | 11804 | 1292 | Python | 288 | Private chat with local GPT with document, images, video, etc. 100% private, Apache 2.0. Supports oLLaMa, Mixtral, llama.cpp, and more. Demo: https://gpt.h2o.ai/ https://gpt-docs.h2o.ai/ | 2025-05-08T08:32:39Z |
| 31 | [ludwig](https://github.com/ludwig-ai/ludwig) | 11449 | 1207 | Python | 40 | Low-code framework for building custom LLMs, neural networks, and other AI models | 2025-05-12T20:02:02Z |
| 32 | [OpenLLM](https://github.com/bentoml/OpenLLM) | 11258 | 719 | Python | 2 | Run any open-source LLMs, such as DeepSeek and Llama, as OpenAI compatible API endpoint in the cloud. | 2025-05-12T23:11:32Z |
| 33 | [llama-gpt](https://github.com/getumbrel/llama-gpt) | 10968 | 710 | TypeScript | 84 | A self-hosted, offline, ChatGPT-like chatbot. Powered by Llama 2. 100% private, with no data leaving your device. New: Code Llama support! | 2024-04-23T18:56:06Z |
| 34 | [shell_gpt](https://github.com/TheR1D/shell_gpt) | 10850 | 858 | Python | 84 | A command-line productivity tool powered by AI large language models like GPT-4, will help you accomplish your tasks faster and more efficiently. | 2025-04-11T08:40:09Z |
| 35 | [petals](https://github.com/bigscience-workshop/petals) | 9619 | 554 | Python | 90 | ğŸŒ¸ Run LLMs at home, BitTorrent-style. Fine-tuning and inference up to 10x faster than offloading | 2024-09-07T11:54:28Z |
| 36 | [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) | 9099 | 1137 | Python | 547 | Python bindings for llama.cpp | 2025-05-08T11:09:37Z |
| 37 | [AstrBot](https://github.com/AstrBotDevs/AstrBot) | 8817 | 591 | Python | 179 | âœ¨ æ˜“ä¸Šæ‰‹çš„å¤šå¹³å° LLM èŠå¤©æœºå™¨äººåŠå¼€å‘æ¡†æ¶ âœ¨ å¹³å°æ”¯æŒ QQã€QQé¢‘é“ã€Telegramã€å¾®ä¿¡ã€ä¼å¾®ã€é£ä¹¦ \| MCP æœåŠ¡å™¨ã€OpenAIã€DeepSeekã€Geminiã€ç¡…åŸºæµåŠ¨ã€æœˆä¹‹æš—é¢ã€Ollamaã€OneAPIã€Dify ç­‰ã€‚é™„å¸¦ WebUIã€‚ | 2025-05-16T03:10:46Z |
| 38 | [TinyLlama](https://github.com/jzhang38/TinyLlama) | 8483 | 531 | Python | 45 | The TinyLlama project is an open endeavor to pretrain a 1.1B Llama model on 3 trillion tokens. | 2024-05-03T20:21:20Z |
| 39 | [bisheng](https://github.com/dataelement/bisheng) | 8482 | 1398 | TypeScript | 101 | BISHENG is an open LLM devops platform for next generation Enterprise AI applications. Powerful and comprehensive features include: GenAI workflow, RAG, Agent, Unified model management, Evaluation, SFT, Dataset Management, Enterprise-level System Management, Observability and more. | 2025-05-15T13:53:14Z |
| 40 | [PowerInfer](https://github.com/SJTU-IPADS/PowerInfer) | 8202 | 431 | C++ | 113 | High-speed Large Language Model Serving for Local Deployment | 2025-02-19T08:15:55Z |
| 41 | [BELLE](https://github.com/LianjiaTech/BELLE) | 8154 | 768 | HTML | 105 | BELLE: Be Everyone's Large Language model Engineï¼ˆå¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹ï¼‰ | 2024-10-16T11:38:59Z |
| 42 | [oumi](https://github.com/oumi-ai/oumi) | 8103 | 593 | Python | 33 | Everything you need to build state-of-the-art foundation models, end-to-end. Easily fine-tune Qwen3, DeepSeek-R1, Llama 4 or any open source LLM and VLM. | 2025-05-16T00:29:32Z |
| 43 | [reor](https://github.com/reorproject/reor) | 7925 | 477 | JavaScript | 106 | Private & local AI personal knowledge management app for high entropy people. | 2025-05-13T21:28:59Z |
| 44 | [ipex-llm](https://github.com/intel/ipex-llm) | 7868 | 1348 | Python | 1148 | Accelerate local LLM inference and finetuning (LLaMA, Mistral, ChatGLM, Qwen, DeepSeek, Mixtral, Gemma, Phi, MiniCPM, Qwen-VL, MiniCPM-V, etc.) on Intel XPU (e.g., local PC with iGPU and NPU, discrete GPU such as Arc, Flex and Max); seamlessly integrate with llama.cpp, Ollama, HuggingFace, LangChain, LlamaIndex, vLLM, DeepSpeed, Axolotl, etc. | 2025-05-15T08:46:52Z |
| 45 | [inference](https://github.com/xorbitsai/inference) | 7823 | 666 | Python | 179 | Replace OpenAI GPT with another LLM in your app by changing a single line of code. Xinference gives you the freedom to use any LLM you need. With Xinference, you're empowered to run inference with any open-source language models, speech recognition models, and multimodal models, whether in the cloud, on-premises, or even on your laptop. | 2025-05-15T11:53:55Z |
| 46 | [llama-stack](https://github.com/meta-llama/llama-stack) | 7787 | 1028 | Python | 126 | Composable building blocks to build Llama Apps | 2025-05-15T20:03:05Z |
| 47 | [ms-swift](https://github.com/modelscope/ms-swift) | 7574 | 642 | Python | 698 | Use PEFT or Full-parameter to CPT/SFT/DPO/GRPO 500+ LLMs (Qwen3, Qwen3-MoE, Llama4, InternLM3, GLM4, Mistral, Yi1.5, DeepSeek-R1, ...) and 200+ MLLMs (Qwen2.5-VL, Qwen2.5-Omni, Qwen2-Audio, Ovis2, InternVL3, Llava, MiniCPM-V-2.6, GLM4v, Xcomposer2.5, DeepSeek-VL2, Phi4, GOT-OCR2, ...). | 2025-05-16T03:14:47Z |
| 48 | [GPTCache](https://github.com/zilliztech/GPTCache) | 7545 | 531 | Python | 70 | Semantic cache for LLMs. Fully integrated with LangChain and llama_index.  | 2024-09-18T02:05:21Z |
| 49 | [langchain4j](https://github.com/langchain4j/langchain4j) | 7524 | 1383 | Java | 414 | Java version of LangChain | 2025-05-15T05:21:16Z |
| 50 | [open_llama](https://github.com/openlm-research/open_llama) | 7488 | 398 | None | 37 | OpenLLaMA, a permissively licensed open source reproduction of Meta AIâ€™s LLaMA 7B trained on the RedPajama dataset | 2023-07-16T13:42:13Z |
| 51 | [Chinese-LLaMA-Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2) | 7158 | 570 | Python | 1 | ä¸­æ–‡LLaMA-2 & Alpaca-2å¤§æ¨¡å‹äºŒæœŸé¡¹ç›® + 64Kè¶…é•¿ä¸Šä¸‹æ–‡æ¨¡å‹ (Chinese LLaMA-2 & Alpaca-2 LLMs with 64K long context models) | 2024-09-23T02:52:19Z |
| 52 | [llama-models](https://github.com/meta-llama/llama-models) | 6995 | 1153 | Python | 107 | Utilities intended for use with Llama models. | 2025-05-07T18:02:56Z |
| 53 | [k8sgpt](https://github.com/k8sgpt-ai/k8sgpt) | 6604 | 812 | Go | 72 | Giving Kubernetes Superpowers to everyone | 2025-05-16T03:21:46Z |
| 54 | [promptfoo](https://github.com/promptfoo/promptfoo) | 6556 | 529 | TypeScript | 161 | Test your prompts, agents, and RAGs. Red teaming, pentesting, and vulnerability scanning for LLMs. Compare performance of GPT, Claude, Gemini, Llama, and more. Simple declarative configs with command line and CI/CD integration. | 2025-05-16T02:08:21Z |
| 55 | [Firefly](https://github.com/yangjianxin1/Firefly) | 6390 | 576 | Python | 204 | Firefly: å¤§æ¨¡å‹è®­ç»ƒå·¥å…·ï¼Œæ”¯æŒè®­ç»ƒQwen2.5ã€Qwen2ã€Yi1.5ã€Phi-3ã€Llama3ã€Gemmaã€MiniCPMã€Yiã€Deepseekã€Orionã€Xverseã€Mixtral-8x7Bã€Zephyrã€Mistralã€Baichuan2ã€Llma2ã€Llamaã€Qwenã€Baichuanã€ChatGLM2ã€InternLMã€Ziya2ã€Vicunaã€Bloomç­‰å¤§æ¨¡å‹ | 2024-10-24T02:27:42Z |
| 56 | [lmdeploy](https://github.com/InternLM/lmdeploy) | 6350 | 542 | Python | 435 | LMDeploy is a toolkit for compressing, deploying, and serving LLMs. | 2025-05-15T11:50:17Z |
| 57 | [lit-llama](https://github.com/Lightning-AI/lit-llama) | 6054 | 522 | Python | 109 | Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. | 2024-09-06T11:38:12Z |
| 58 | [llamacoder](https://github.com/Nutlope/llamacoder) | 6003 | 1407 | TypeScript | 43 | Open source Claude Artifacts â€“ built with Llama 3.1 405B | 2025-04-08T15:15:38Z |
| 59 | [LaWGPT](https://github.com/pengxiao-song/LaWGPT) | 5972 | 552 | Python | 86 |  ğŸ‰ Repo for LaWGPT, Chinese-Llama tuned with Chinese Legal knowledge. åŸºäºä¸­æ–‡æ³•å¾‹çŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹ | 2024-06-11T07:20:19Z |
| 60 | [LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter) | 5872 | 382 | Python | 107 | [ICLR 2024] Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters | 2024-03-14T08:12:53Z |
| 61 | [airllm](https://github.com/lyogavin/airllm) | 5771 | 457 | Jupyter Notebook | 112 | AirLLM 70B inference with single 4GB GPU | 2025-05-06T13:11:40Z |
| 62 | [serge](https://github.com/serge-chat/serge) | 5718 | 400 | Svelte | 18 | A web interface for chatting with Alpaca through llama.cpp. Fully dockerized, with an easy to use API. | 2025-05-15T08:21:37Z |
| 63 | [mergekit](https://github.com/arcee-ai/mergekit) | 5712 | 545 | Python | 207 | Tools for merging pretrained large language models. | 2025-05-14T01:34:49Z |
| 64 | [Baichuan-7B](https://github.com/baichuan-inc/Baichuan-7B) | 5689 | 505 | Python | 85 | A large-scale 7B pretraining language model developed by BaiChuan-Inc. | 2024-07-18T14:23:01Z |
| 65 | [enchanted](https://github.com/gluonfield/enchanted) | 5312 | 342 | Swift | 92 | Enchanted is iOS and macOS app for chatting with private self hosted language models such as Llama2, Mistral or Vicuna using Ollama. | 2025-03-19T20:19:21Z |
| 66 | [llama-fs](https://github.com/iyaja/llama-fs) | 5279 | 335 | TypeScript | 50 | A self-organizing file system with llama 3 | 2025-02-18T01:58:14Z |
| 67 | [awesome-LLM-resources](https://github.com/WangRongsheng/awesome-LLM-resources) | 5195 | 512 | None | 0 | ğŸ§‘â€ğŸš€ å…¨ä¸–ç•Œæœ€å¥½çš„LLMèµ„æ–™æ€»ç»“ï¼ˆAgentæ¡†æ¶ã€è¾…åŠ©ç¼–ç¨‹ã€æ•°æ®å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€æ¨¡å‹æ¨ç†ã€o1 æ¨¡å‹ã€MCPã€å°è¯­è¨€æ¨¡å‹ã€è§†è§‰è¯­è¨€æ¨¡å‹ï¼‰ \| Summary of the world's best LLM resources.  | 2025-05-13T13:11:02Z |
| 68 | [Liger-Kernel](https://github.com/linkedin/Liger-Kernel) | 5019 | 324 | Python | 59 | Efficient Triton Kernels for LLM Training | 2025-05-15T16:35:49Z |
| 69 | [YuE](https://github.com/multimodal-art-projection/YuE) | 4969 | 544 | Python | 64 | YuE: Open Full-song Music Generation Foundation Model, something similar to Suno.ai but open | 2025-05-15T07:04:03Z |
| 70 | [llm-answer-engine](https://github.com/developersdigest/llm-answer-engine) | 4896 | 763 | TypeScript | 25 | Build a Perplexity-Inspired Answer Engine Using Next.js, Groq, Llama-3, Langchain, OpenAI, Upstash, Brave & Serper | 2024-09-28T16:41:53Z |
| 71 | [llm-scraper](https://github.com/mishushakov/llm-scraper) | 4860 | 281 | TypeScript | 11 | Turn any webpage into structured data using LLMs | 2024-08-30T17:36:16Z |
| 72 | [Huatuo-Llama-Med-Chinese](https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese) | 4769 | 479 | Python | 28 | Repo for BenTsao [original name: HuaTuo (åé©¼)], Instruction-tuning Large Language Models with Chinese Medical Knowledge. æœ¬è‰ï¼ˆåŸåï¼šåé©¼ï¼‰æ¨¡å‹ä»“åº“ï¼ŒåŸºäºä¸­æ–‡åŒ»å­¦çŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹æŒ‡ä»¤å¾®è°ƒ | 2025-02-21T02:04:37Z |
| 73 | [data-juicer](https://github.com/modelscope/data-juicer) | 4410 | 235 | Python | 33 | Data processing for and with foundation models!  ğŸ ğŸ‹ ğŸŒ½ â¡ï¸ â¡ï¸ğŸ¸ ğŸ¹ ğŸ· | 2025-05-15T21:45:59Z |
| 74 | [GPT-4-LLM](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM) | 4304 | 306 | HTML | 13 | Instruction Tuning with GPT-4 | 2023-06-11T13:40:30Z |
| 75 | [h2o-llmstudio](https://github.com/h2oai/h2o-llmstudio) | 4303 | 445 | Python | 37 | H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs. Documentation: https://docs.h2o.ai/h2o-llmstudio/ | 2025-04-10T14:42:59Z |
| 76 | [llama-stack-apps](https://github.com/meta-llama/llama-stack-apps) | 4231 | 621 | None | 20 | Agentic components of the Llama Stack APIs | 2025-04-30T18:01:33Z |
| 77 | [g1](https://github.com/bklieger-groq/g1) | 4214 | 379 | Python | 1 | g1: Using Llama-3.1 70b on Groq to create o1-like reasoning chains | 2025-01-27T18:36:13Z |
| 78 | [llama-dl](https://github.com/shawwn/llama-dl) | 4164 | 417 | Shell | 9 | High-speed download of LLaMA, Facebook's 65B parameter GPT model | 2023-06-28T16:56:55Z |
| 79 | [Chinese-Vicuna](https://github.com/Facico/Chinese-Vicuna) | 4153 | 417 | C | 65 | Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model â€”â€” ä¸€ä¸ªä¸­æ–‡ä½èµ„æºçš„llama+loraæ–¹æ¡ˆï¼Œç»“æ„å‚è€ƒalpaca | 2025-04-18T02:41:35Z |
| 80 | [llama3-Chinese-chat](https://github.com/CrazyBoyM/llama3-Chinese-chat) | 4148 | 340 | Python | 29 | Llama3ã€Llama3.1 ä¸­æ–‡åè®­ç»ƒç‰ˆä»“åº“ - å¾®è°ƒã€é­”æ”¹ç‰ˆæœ¬æœ‰è¶£æƒé‡ & è®­ç»ƒã€æ¨ç†ã€è¯„æµ‹ã€éƒ¨ç½²æ•™ç¨‹è§†é¢‘ & æ–‡æ¡£ã€‚ | 2025-05-07T06:09:40Z |
| 81 | [tensorzero](https://github.com/tensorzero/tensorzero) | 4147 | 275 | Rust | 176 | TensorZero creates a feedback loop for optimizing LLM applications â€” turning production data into smarter, faster, and cheaper models. | 2025-05-15T23:15:59Z |
| 82 | [llama_cloud_services](https://github.com/run-llama/llama_cloud_services) | 3968 | 412 | Python | 239 | Knowledge Agents and Management in the Cloud | 2025-05-09T21:03:13Z |
| 83 | [MedicalGPT](https://github.com/shibing624/MedicalGPT) | 3884 | 570 | Python | 46 | MedicalGPT: Training Your Own Medical GPT Model with ChatGPT Training Pipeline. è®­ç»ƒåŒ»ç–—å¤§æ¨¡å‹ï¼Œå®ç°äº†åŒ…æ‹¬å¢é‡é¢„è®­ç»ƒ(PT)ã€æœ‰ç›‘ç£å¾®è°ƒ(SFT)ã€RLHFã€DPOã€ORPOã€GRPOã€‚ | 2025-04-18T06:28:34Z |
| 84 | [obsidian-smart-connections](https://github.com/brianpetro/obsidian-smart-connections) | 3650 | 212 | JavaScript | 356 | Chat with your notes & see links to related content with AI embeddings. Use local models or 100+ via APIs like Claude, Gemini, ChatGPT & Llama 3 | 2025-05-15T17:40:03Z |
| 85 | [casibase](https://github.com/casibase/casibase) | 3611 | 422 | Go | 28 | âš¡ï¸AI Cloud OS: Open-source enterprise-level AI knowledge base and MCP (model-context-protocol)/A2A (agent-to-agent) management platform with admin UI, user management and Single-Sign-Onâš¡ï¸, supports ChatGPT, Claude, Llama, Ollama, HuggingFace, etc., chat bot demo: https://ai.casibase.com, admin UI demo: https://ai-admin.casibase.com | 2025-05-13T16:49:44Z |
| 86 | [llama-hub](https://github.com/run-llama/llama-hub) | 3479 | 729 | Jupyter Notebook | 82 | A library of data loaders for LLMs made by the community -- to be used with LlamaIndex and/or LangChain | 2024-03-01T15:17:16Z |
| 87 | [zero_nlp](https://github.com/yuanzhoulvpi2017/zero_nlp) | 3445 | 406 | Jupyter Notebook | 100 | ä¸­æ–‡nlpè§£å†³æ–¹æ¡ˆ(å¤§æ¨¡å‹ã€æ•°æ®ã€æ¨¡å‹ã€è®­ç»ƒã€æ¨ç†)  | 2025-02-12T13:56:56Z |
| 88 | [higgsfield](https://github.com/higgsfield-ai/higgsfield) | 3371 | 569 | Jupyter Notebook | 1 | Fault-tolerant, highly scalable GPU orchestration, and a machine learning framework designed for training models with billions to trillions of parameters | 2024-05-25T17:43:07Z |
| 89 | [PurpleLlama](https://github.com/meta-llama/PurpleLlama) | 3321 | 550 | Python | 8 | Set of tools to assess and improve LLM security. | 2025-05-15T23:52:26Z |
| 90 | [langroid](https://github.com/langroid/langroid) | 3302 | 318 | Python | 55 | Harness LLMs with Multi-Agent Programming | 2025-05-16T02:07:26Z |
| 91 | [transformerlab-app](https://github.com/transformerlab/transformerlab-app) | 3289 | 271 | TypeScript | 44 | Open Source Application for Advanced LLM Engineering: interact, train, fine-tune, and evaluate large language models on your own computer. | 2025-05-15T22:10:27Z |
| 92 | [LangChain-ChatGLM-Webui](https://github.com/X-D-Lab/LangChain-ChatGLM-Webui) | 3262 | 494 | Python | 45 | åŸºäºLangChainå’ŒChatGLM-6Bç­‰ç³»åˆ—LLMçš„é’ˆå¯¹æœ¬åœ°çŸ¥è¯†åº“çš„è‡ªåŠ¨é—®ç­” | 2024-04-15T15:03:05Z |
| 93 | [YAYI](https://github.com/wenge-research/YAYI) | 3262 | 44 | Python | 0 | é›…æ„å¤§æ¨¡å‹ï¼šä¸ºå®¢æˆ·æ‰“é€ å®‰å…¨å¯é çš„ä¸“å±å¤§æ¨¡å‹ï¼ŒåŸºäºå¤§è§„æ¨¡ä¸­è‹±æ–‡å¤šé¢†åŸŸæŒ‡ä»¤æ•°æ®è®­ç»ƒçš„ LlaMA 2 & BLOOM ç³»åˆ—æ¨¡å‹ï¼Œç”±ä¸­ç§‘é—»æ­Œç®—æ³•å›¢é˜Ÿç ”å‘ã€‚(Repo for YaYi Chinese LLMs based on LlaMA2 & BLOOM) | 2024-01-17T07:37:16Z |
| 94 | [lightllm](https://github.com/ModelTC/lightllm) | 3221 | 254 | Python | 76 | LightLLM is a Python-based LLM (Large Language Model) inference and serving framework, notable for its lightweight design, easy scalability, and high-speed performance. | 2025-05-16T03:21:39Z |
| 95 | [free-llm-api-resources](https://github.com/cheahjs/free-llm-api-resources) | 3220 | 282 | Python | 4 | A list of free LLM inference resources accessible via API. | 2025-05-16T01:27:17Z |
| 96 | [InternGPT](https://github.com/OpenGVLab/InternGPT) | 3213 | 230 | Python | 19 | InternGPT (iGPT) is an open source demo platform where you can easily showcase your AI models. Now it supports DragGAN, ChatGPT, ImageBind, multimodal chat like GPT-4, SAM, interactive image editing, etc. Try it at igpt.opengvlab.com (æ”¯æŒDragGANã€ChatGPTã€ImageBindã€SAMçš„åœ¨çº¿Demoç³»ç»Ÿ) | 2024-08-20T12:51:03Z |
| 97 | [LLamaSharp](https://github.com/SciSharp/LLamaSharp) | 3194 | 423 | C# | 94 | A C#/.NET library to run LLM (ğŸ¦™LLaMA/LLaVA) on your local device efficiently. | 2025-05-15T13:55:45Z |
| 98 | [paperless-ai](https://github.com/clusterzx/paperless-ai) | 3122 | 115 | JavaScript | 15 | An automated document analyzer for Paperless-ngx using OpenAI API, Ollama, Deepseek-r1, Azure and all OpenAI API compatible Services to automatically analyze and tag your documents. | 2025-05-15T19:08:27Z |
| 99 | [Linly](https://github.com/CVI-SZU/Linly) | 3054 | 232 | Python | 109 | Chinese-LLaMA 1&2ã€Chinese-Falcon åŸºç¡€æ¨¡å‹ï¼›ChatFlowä¸­æ–‡å¯¹è¯æ¨¡å‹ï¼›ä¸­æ–‡OpenLLaMAæ¨¡å‹ï¼›NLPé¢„è®­ç»ƒ/æŒ‡ä»¤å¾®è°ƒæ•°æ®é›† | 2024-04-14T05:19:19Z |
| 100 | [GPTQ-for-LLaMa](https://github.com/qwopqwop200/GPTQ-for-LLaMa) | 3051 | 460 | Python | 61 | 4 bits quantization of LLaMA using GPTQ | 2024-07-13T04:45:28Z |

