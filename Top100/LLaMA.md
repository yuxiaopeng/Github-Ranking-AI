[Github Ranking](../README.md)
==========

## Top 100 Stars in LLaMA

| Ranking | Project Name | Stars | Forks | Language | Open Issues | Description | Last Commit |
| ------- | ------------ | ----- | ----- | -------- | ----------- | ----------- | ----------- |
| 1 | [ollama](https://github.com/ollama/ollama) | 160047 | 14205 | Go | 1897 | Get up and running with OpenAI gpt-oss, DeepSeek-R1, Gemma 3 and other models. | 2026-01-21T02:30:03Z |
| 2 | [llama.cpp](https://github.com/ggml-org/llama.cpp) | 93392 | 14547 | C++ | 362 | LLM inference in C/C++ | 2026-01-21T01:34:29Z |
| 3 | [vllm](https://github.com/vllm-project/vllm) | 67971 | 12732 | Python | 1716 | A high-throughput and memory-efficient inference and serving engine for LLMs | 2026-01-21T03:24:05Z |
| 4 | [LlamaFactory](https://github.com/hiyouga/LlamaFactory) | 66199 | 8044 | Python | 860 | Unified Efficient Fine-Tuning of 100+ LLMs & VLMs (ACL 2024) | 2026-01-20T07:54:08Z |
| 5 | [llama](https://github.com/meta-llama/llama) | 59075 | 9814 | Python | 458 | Inference code for Llama models | 2025-01-26T21:42:26Z |
| 6 | [unsloth](https://github.com/unslothai/unsloth) | 50952 | 4201 | Python | 828 | Fine-tuning & Reinforcement Learning for LLMs. ğŸ¦¥ Train OpenAI gpt-oss, DeepSeek, Qwen, Llama, Gemma, TTS 2x faster with 70% less VRAM. | 2026-01-20T09:02:41Z |
| 7 | [llama_index](https://github.com/run-llama/llama_index) | 46498 | 6718 | Python | 249 | LlamaIndex is the leading framework for building LLM-powered agents over your data. | 2026-01-19T11:50:30Z |
| 8 | [LocalAI](https://github.com/mudler/LocalAI) | 42218 | 3462 | Go | 138 | :robot: The free, Open Source alternative to OpenAI, Claude and others. Self-hosted and local-first. Drop-in replacement for OpenAI,  running on consumer-grade hardware. No GPU required. Runs gguf, transformers, diffusers and many more. Features: Generate Text, MCP, Audio, Video, Images, Voice Cloning, Distributed, P2P and decentralized inference | 2026-01-20T23:12:15Z |
| 9 | [aider](https://github.com/Aider-AI/aider) | 39933 | 3826 | Python | 1133 | aider is AI pair programming in your terminal | 2026-01-19T15:39:28Z |
| 10 | [quivr](https://github.com/QuivrHQ/quivr) | 38860 | 3721 | Python | 1 | Opiniated RAG for integrating GenAI in your apps ğŸ§    Focus on your product rather than the RAG. Easy integration in existing products with customisation!  Any LLM: GPT4, Groq, Llama. Any Vectorstore: PGVector, Faiss. Any Files. Anyway you want.  | 2025-07-09T12:55:23Z |
| 11 | [Langchain-Chatchat](https://github.com/chatchat-space/Langchain-Chatchat) | 37137 | 6133 | Python | 21 | Langchain-Chatchatï¼ˆåŸLangchain-ChatGLMï¼‰åŸºäº Langchain ä¸ ChatGLM, Qwen ä¸ Llama ç­‰è¯­è¨€æ¨¡å‹çš„ RAG ä¸ Agent åº”ç”¨ \| Langchain-Chatchat (formerly langchain-ChatGLM), local knowledge based LLM (like ChatGLM, Qwen and Llama) RAG and Agent app with langchain  | 2025-11-10T09:27:42Z |
| 12 | [khoj](https://github.com/khoj-ai/khoj) | 32232 | 1931 | Python | 77 | Your AI second brain. Self-hostable. Get answers from the web or your docs. Build custom agents, schedule automations, do deep research. Turn any online or local LLM into your personal, autonomous AI (gpt, claude, gemini, llama, qwen, mistral). Get started - free. | 2026-01-06T20:15:01Z |
| 13 | [llama3](https://github.com/meta-llama/llama3) | 29185 | 3509 | Python | 178 | The official Meta Llama 3 GitHub site | 2025-01-26T21:39:06Z |
| 14 | [fish-speech](https://github.com/fishaudio/fish-speech) | 24658 | 2045 | Python | 17 | SOTA Open Source TTS | 2026-01-08T08:43:07Z |
| 15 | [LLaVA](https://github.com/haotian-liu/LLaVA) | 24342 | 2707 | Python | 1091 | [NeurIPS'23 Oral] Visual Instruction Tuning (LLaVA) built towards GPT-4V level capabilities and beyond. | 2024-08-12T09:52:38Z |
| 16 | [llamafile](https://github.com/mozilla-ai/llamafile) | 23645 | 1259 | C | 189 | Distribute and run LLMs with a single file. | 2026-01-20T10:55:33Z |
| 17 | [sglang](https://github.com/sgl-project/sglang) | 22617 | 4128 | Python | 649 | SGLang is a high-performance serving framework for large language models and multimodal models. | 2026-01-21T04:06:30Z |
| 18 | [Awesome-Chinese-LLM](https://github.com/HqWu-HITCS/Awesome-Chinese-LLM) | 22123 | 2100 | None | 5 | æ•´ç†å¼€æºçš„ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹ï¼Œä»¥è§„æ¨¡è¾ƒå°ã€å¯ç§æœ‰åŒ–éƒ¨ç½²ã€è®­ç»ƒæˆæœ¬è¾ƒä½çš„æ¨¡å‹ä¸ºä¸»ï¼ŒåŒ…æ‹¬åº•åº§æ¨¡å‹ï¼Œå‚ç›´é¢†åŸŸå¾®è°ƒåŠåº”ç”¨ï¼Œæ•°æ®é›†ä¸æ•™ç¨‹ç­‰ã€‚ | 2025-05-19T06:11:57Z |
| 19 | [repomix](https://github.com/yamadashy/repomix) | 21364 | 994 | TypeScript | 121 | ğŸ“¦ Repomix is a powerful tool that packs your entire repository into a single, AI-friendly file. Perfect for when you need to feed your codebase to Large Language Models (LLMs) or other AI tools like Claude, ChatGPT, DeepSeek, Perplexity, Gemini, Gemma, Llama, Grok, and more. | 2026-01-18T15:41:46Z |
| 20 | [llama2.c](https://github.com/karpathy/llama2.c) | 19124 | 2437 | C | 125 | Inference Llama 2 in one file of pure C | 2024-08-06T09:44:40Z |
| 21 | [alpaca-lora](https://github.com/tloen/alpaca-lora) | 18977 | 2215 | Jupyter Notebook | 333 | Instruct-tune LLaMA on consumer hardware | 2024-07-29T13:37:49Z |
| 22 | [Chinese-LLaMA-Alpaca](https://github.com/ymcui/Chinese-LLaMA-Alpaca) | 18974 | 1871 | Python | 1 | ä¸­æ–‡LLaMA&Alpacaå¤§è¯­è¨€æ¨¡å‹+æœ¬åœ°CPU/GPUè®­ç»ƒéƒ¨ç½² (Chinese LLaMA & Alpaca LLMs) | 2025-07-15T00:53:02Z |
| 23 | [llama-cookbook](https://github.com/meta-llama/llama-cookbook) | 18160 | 2690 | Jupyter Notebook | 23 | Welcome to the Llama Cookbook! This is your go to guide for Building with Llama: Getting started with Inference, Fine-Tuning, RAG. We also show you how to solve end to end problems using Llama model family and using them on various provider services   | 2025-11-03T16:25:20Z |
| 24 | [ChuanhuChatGPT](https://github.com/GaiZhenbiao/ChuanhuChatGPT) | 15401 | 2264 | Python | 124 | GUI for ChatGPT API and many LLMs. Supports agents, file-based QA, GPT finetuning and query with web search. All with a neat UI. | 2025-08-15T02:25:50Z |
| 25 | [llama3-from-scratch](https://github.com/naklecha/llama3-from-scratch) | 15238 | 1287 | Jupyter Notebook | 14 | llama3 implementation one matrix multiplication at a time | 2024-05-23T14:34:05Z |
| 26 | [AstrBot](https://github.com/AstrBotDevs/AstrBot) | 15105 | 1183 | Python | 387 | Agentic IM Chatbot infrastructure that integrates lots of IM platforms, LLMs, plugins and AI features. âœ¨ | 2026-01-20T02:23:37Z |
| 27 | [Llama-Chinese](https://github.com/LlamaFamily/Llama-Chinese) | 14749 | 1306 | Python | 195 | Llamaä¸­æ–‡ç¤¾åŒºï¼Œå®æ—¶æ±‡æ€»æœ€æ–°Llamaå­¦ä¹ èµ„æ–™ï¼Œæ„å»ºæœ€å¥½çš„ä¸­æ–‡Llamaå¤§æ¨¡å‹å¼€æºç”Ÿæ€ï¼Œå®Œå…¨å¼€æºå¯å•†ç”¨ | 2025-04-06T09:16:55Z |
| 28 | [dalai](https://github.com/cocktailpeanut/dalai) | 13006 | 1368 | CSS | 291 | The simplest way to run LLaMA on your local machine | 2024-06-18T20:29:46Z |
| 29 | [PaddleNLP](https://github.com/PaddlePaddle/PaddleNLP) | 12902 | 3070 | Python | 121 | Easy-to-use and powerful LLM and SLM library with awesome model zoo. | 2025-12-17T09:19:22Z |
| 30 | [ms-swift](https://github.com/modelscope/ms-swift) | 12258 | 1148 | Python | 727 | Use PEFT or Full-parameter to CPT/SFT/DPO/GRPO 600+ LLMs (Qwen3, Qwen3-MoE, DeepSeek-R1, GLM4.5, InternLM3, Llama4, ...) and 300+ MLLMs (Qwen3-VL, Qwen3-Omni, InternVL3.5, Ovis2.5, GLM4.5v, Llava, Phi4, ...) (AAAI 2025). | 2026-01-21T03:33:05Z |
| 31 | [OpenLLM](https://github.com/bentoml/OpenLLM) | 12058 | 797 | Python | 3 | Run any open-source LLMs, such as DeepSeek and Llama, as OpenAI compatible API endpoint in the cloud. | 2026-01-19T16:57:19Z |
| 32 | [h2ogpt](https://github.com/h2oai/h2ogpt) | 12005 | 1315 | Python | 293 | Private chat with local GPT with document, images, video, etc. 100% private, Apache 2.0. Supports oLLaMa, Mixtral, llama.cpp, and more. Demo: https://gpt.h2o.ai/ https://gpt-docs.h2o.ai/ | 2025-10-09T23:30:01Z |
| 33 | [shell_gpt](https://github.com/TheR1D/shell_gpt) | 11675 | 939 | Python | 93 | A command-line productivity tool powered by AI large language models like GPT-4, will help you accomplish your tasks faster and more efficiently. | 2025-10-30T03:33:26Z |
| 34 | [ludwig](https://github.com/ludwig-ai/ludwig) | 11641 | 1213 | Python | 42 | Low-code framework for building custom LLMs, neural networks, and other AI models | 2026-01-19T21:23:59Z |
| 35 | [llama-gpt](https://github.com/getumbrel/llama-gpt) | 10992 | 714 | TypeScript | 84 | A self-hosted, offline, ChatGPT-like chatbot. Powered by Llama 2. 100% private, with no data leaving your device. New: Code Llama support! | 2024-04-23T18:56:06Z |
| 36 | [bisheng](https://github.com/dataelement/bisheng) | 10962 | 1791 | TypeScript | 91 | BISHENG is an open LLM devops platform for next generation Enterprise AI applications. Powerful and comprehensive features include: GenAI workflow, RAG, Agent, Unified model management, Evaluation, SFT, Dataset Management, Enterprise-level System Management, Observability and more. | 2026-01-21T03:33:24Z |
| 37 | [tensorzero](https://github.com/tensorzero/tensorzero) | 10844 | 752 | Rust | 293 | TensorZero is an open-source stack for industrial-grade LLM applications. It unifies an LLM gateway, observability, optimization, evaluation, and experimentation. | 2026-01-21T04:03:01Z |
| 38 | [langchain4j](https://github.com/langchain4j/langchain4j) | 10456 | 1913 | Java | 558 | LangChain4j is an open-source Java library that simplifies the integration of LLMs into Java applications through a unified API, providing access to popular LLMs and vector databases. It makes implementing RAG, tool calling (including support for MCP), and agents easy. LangChain4j integrates seamlessly with various enterprise Java frameworks. | 2026-01-20T07:22:04Z |
| 39 | [promptfoo](https://github.com/promptfoo/promptfoo) | 10029 | 880 | TypeScript | 76 | Test your prompts, agents, and RAGs. AI Red teaming, pentesting, and vulnerability scanning for LLMs. Compare performance of GPT, Claude, Gemini, Llama, and more. Simple declarative configs with command line and CI/CD integration. | 2026-01-21T04:11:13Z |
| 40 | [llama-cpp-python](https://github.com/abetlen/llama-cpp-python) | 9914 | 1274 | Python | 589 | Python bindings for llama.cpp | 2025-08-15T06:23:26Z |
| 41 | [petals](https://github.com/bigscience-workshop/petals) | 9879 | 586 | Python | 92 | ğŸŒ¸ Run LLMs at home, BitTorrent-style. Fine-tuning and inference up to 10x faster than offloading | 2024-09-07T11:54:28Z |
| 42 | [inference](https://github.com/xorbitsai/inference) | 8973 | 788 | Python | 136 | Swap GPT for any LLM by changing a single line of code. Xinference lets you run open-source, speech, and multimodal models on cloud, on-prem, or your laptop â€” all through one unified, production-ready inference API. | 2026-01-20T13:19:45Z |
| 43 | [TinyLlama](https://github.com/jzhang38/TinyLlama) | 8872 | 589 | Python | 45 | The TinyLlama project is an open endeavor to pretrain a 1.1B Llama model on 3 trillion tokens. | 2024-05-03T20:21:20Z |
| 44 | [oumi](https://github.com/oumi-ai/oumi) | 8829 | 695 | Python | 6 | Easily fine-tune, evaluate and deploy gpt-oss, Qwen3, DeepSeek-R1, or any open source LLM / VLM! | 2026-01-21T00:11:17Z |
| 45 | [ipex-llm](https://github.com/intel/ipex-llm) | 8630 | 1397 | Python | 1214 | Accelerate local LLM inference and finetuning (LLaMA, Mistral, ChatGLM, Qwen, DeepSeek, Mixtral, Gemma, Phi, MiniCPM, Qwen-VL, MiniCPM-V, etc.) on Intel XPU (e.g., local PC with iGPU and NPU, discrete GPU such as Arc, Flex and Max); seamlessly integrate with llama.cpp, Ollama, HuggingFace, LangChain, LlamaIndex, vLLM, DeepSpeed, Axolotl, etc. | 2025-10-14T06:04:12Z |
| 46 | [PowerInfer](https://github.com/SJTU-IPADS/PowerInfer) | 8586 | 476 | C++ | 120 | High-speed Large Language Model Serving for Local Deployment | 2025-08-02T03:36:13Z |
| 47 | [reor](https://github.com/reorproject/reor) | 8467 | 515 | JavaScript | 111 | Private & local AI personal knowledge management app for high entropy people. | 2025-05-13T21:28:59Z |
| 48 | [ART](https://github.com/OpenPipe/ART) | 8303 | 665 | Python | 57 | Agent Reinforcement Trainer: train multi-step agents for real-world tasks using GRPO. Give your agents on-the-job training. Reinforcement learning for Qwen2.5, Qwen3, Llama, and more! | 2026-01-20T21:56:32Z |
| 49 | [BELLE](https://github.com/LianjiaTech/BELLE) | 8283 | 768 | HTML | 106 | BELLE: Be Everyone's Large Language model Engineï¼ˆå¼€æºä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹ï¼‰ | 2024-10-16T11:38:59Z |
| 50 | [llama-stack](https://github.com/llamastack/llama-stack) | 8241 | 1249 | Python | 171 | Composable building blocks to build LLM Apps | 2026-01-20T20:54:59Z |
| 51 | [free-llm-api-resources](https://github.com/cheahjs/free-llm-api-resources) | 7920 | 770 | Python | 10 | A list of free LLM inference resources accessible via API. | 2026-01-21T01:02:13Z |
| 52 | [GPTCache](https://github.com/zilliztech/GPTCache) | 7909 | 570 | Python | 74 | Semantic cache for LLMs. Fully integrated with LangChain and llama_index.  | 2025-07-11T09:04:36Z |
| 53 | [nexa-sdk](https://github.com/NexaAI/nexa-sdk) | 7551 | 942 | Go | 25 | Run frontier LLMs and VLMs with day-0 model support across GPU, NPU, and CPU, with comprehensive runtime coverage for PC (Python/C++), mobile (Android & iOS), and Linux/IoT (Arm64 & x86 Docker). Supporting OpenAI GPT-OSS, IBM Granite-4, Qwen-3-VL, Gemma-3n, Ministral-3, and more. | 2026-01-21T04:07:18Z |
| 54 | [lmdeploy](https://github.com/InternLM/lmdeploy) | 7539 | 647 | Python | 512 | LMDeploy is a toolkit for compressing, deploying, and serving LLMs. | 2026-01-20T07:47:55Z |
| 55 | [open_llama](https://github.com/openlm-research/open_llama) | 7525 | 409 | None | 37 | OpenLLaMA, a permissively licensed open source reproduction of Meta AIâ€™s LLaMA 7B trained on the RedPajama dataset | 2023-07-16T13:42:13Z |
| 56 | [airllm](https://github.com/lyogavin/airllm) | 7505 | 685 | Jupyter Notebook | 119 | AirLLM 70B inference with single 4GB GPU | 2025-09-03T13:50:08Z |
| 57 | [llama-models](https://github.com/meta-llama/llama-models) | 7436 | 1313 | Python | 163 | Utilities intended for use with Llama models. | 2026-01-08T04:48:21Z |
| 58 | [awesome-LLM-resources](https://github.com/WangRongsheng/awesome-LLM-resources) | 7345 | 717 | None | 0 | ğŸ§‘â€ğŸš€ å…¨ä¸–ç•Œæœ€å¥½çš„LLMèµ„æ–™æ€»ç»“ï¼ˆå¤šæ¨¡æ€ç”Ÿæˆã€Agentã€è¾…åŠ©ç¼–ç¨‹ã€AIå®¡ç¨¿ã€æ•°æ®å¤„ç†ã€æ¨¡å‹è®­ç»ƒã€æ¨¡å‹æ¨ç†ã€o1 æ¨¡å‹ã€MCPã€å°è¯­è¨€æ¨¡å‹ã€è§†è§‰è¯­è¨€æ¨¡å‹ï¼‰ \| Summary of the world's best LLM resources.  | 2026-01-20T06:08:14Z |
| 59 | [k8sgpt](https://github.com/k8sgpt-ai/k8sgpt) | 7339 | 929 | Go | 89 | Giving Kubernetes Superpowers to everyone | 2026-01-21T01:09:26Z |
| 60 | [Chinese-LLaMA-Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2) | 7176 | 566 | Python | 1 | ä¸­æ–‡LLaMA-2 & Alpaca-2å¤§æ¨¡å‹äºŒæœŸé¡¹ç›® + 64Kè¶…é•¿ä¸Šä¸‹æ–‡æ¨¡å‹ (Chinese LLaMA-2 & Alpaca-2 LLMs with 64K long context models) | 2025-07-15T00:47:22Z |
| 61 | [llamacoder](https://github.com/Nutlope/llamacoder) | 6827 | 1645 | TypeScript | 3 | Open source Claude Artifacts â€“ built with Llama 3.1 405B | 2025-12-17T10:53:14Z |
| 62 | [mergekit](https://github.com/arcee-ai/mergekit) | 6696 | 654 | Python | 233 | Tools for merging pretrained large language models. | 2026-01-02T15:34:18Z |
| 63 | [Firefly](https://github.com/yangjianxin1/Firefly) | 6634 | 586 | Python | 203 | Firefly: å¤§æ¨¡å‹è®­ç»ƒå·¥å…·ï¼Œæ”¯æŒè®­ç»ƒQwen2.5ã€Qwen2ã€Yi1.5ã€Phi-3ã€Llama3ã€Gemmaã€MiniCPMã€Yiã€Deepseekã€Orionã€Xverseã€Mixtral-8x7Bã€Zephyrã€Mistralã€Baichuan2ã€Llma2ã€Llamaã€Qwenã€Baichuanã€ChatGLM2ã€InternLMã€Ziya2ã€Vicunaã€Bloomç­‰å¤§æ¨¡å‹ | 2024-10-24T02:27:42Z |
| 64 | [llm-scraper](https://github.com/mishushakov/llm-scraper) | 6162 | 368 | TypeScript | 9 | Turn any webpage into structured data using LLMs | 2025-12-06T22:12:24Z |
| 65 | [lit-llama](https://github.com/Lightning-AI/lit-llama) | 6093 | 525 | Python | 100 | Implementation of the LLaMA language model based on nanoGPT. Supports flash attention, Int8 and GPTQ 4bit quantization, LoRA and LLaMA-Adapter fine-tuning, pre-training. Apache 2.0-licensed. | 2025-07-01T16:31:39Z |
| 66 | [Liger-Kernel](https://github.com/linkedin/Liger-Kernel) | 6054 | 468 | Python | 89 | Efficient Triton Kernels for LLM Training | 2026-01-21T00:08:32Z |
| 67 | [LaWGPT](https://github.com/pengxiao-song/LaWGPT) | 6027 | 553 | Python | 86 |  ğŸ‰ Repo for LaWGPT, Chinese-Llama tuned with Chinese Legal knowledge. åŸºäºä¸­æ–‡æ³•å¾‹çŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹ | 2024-06-11T07:20:19Z |
| 68 | [YuE](https://github.com/multimodal-art-projection/YuE) | 5963 | 703 | Python | 82 | YuE: Open Full-song Music Generation Foundation Model, something similar to Suno.ai but open | 2025-06-04T13:08:48Z |
| 69 | [LLaMA-Adapter](https://github.com/OpenGVLab/LLaMA-Adapter) | 5936 | 379 | Python | 107 | [ICLR 2024] Fine-tuning LLaMA to follow Instructions within 1 Hour and 1.2M Parameters | 2024-03-14T08:12:53Z |
| 70 | [enchanted](https://github.com/gluonfield/enchanted) | 5780 | 399 | Swift | 99 | Enchanted is iOS and macOS app for chatting with private self hosted language models such as Llama2, Mistral or Vicuna using Ollama. | 2025-03-19T20:19:21Z |
| 71 | [serge](https://github.com/serge-chat/serge) | 5751 | 401 | Svelte | 18 | A web interface for chatting with Alpaca through llama.cpp. Fully dockerized, with an easy to use API. | 2025-11-21T08:07:36Z |
| 72 | [llama-fs](https://github.com/iyaja/llama-fs) | 5703 | 388 | TypeScript | 53 | A self-organizing file system with llama 3 | 2025-08-08T02:27:02Z |
| 73 | [Baichuan-7B](https://github.com/baichuan-inc/Baichuan-7B) | 5683 | 506 | Python | 85 | A large-scale 7B pretraining language model developed by BaiChuan-Inc. | 2024-07-18T14:23:01Z |
| 74 | [smolvlm-realtime-webcam](https://github.com/ngxson/smolvlm-realtime-webcam) | 5492 | 889 | HTML | 12 | Real-time webcam demo with SmolVLM and llama.cpp server | 2025-05-12T17:24:39Z |
| 75 | [paperless-ai](https://github.com/clusterzx/paperless-ai) | 4984 | 239 | JavaScript | 34 | An automated document analyzer for Paperless-ngx using OpenAI API, Ollama, Deepseek-r1, Azure and all OpenAI API compatible Services to automatically analyze and tag your documents. | 2026-01-15T01:06:07Z |
| 76 | [Huatuo-Llama-Med-Chinese](https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese) | 4932 | 499 | Python | 28 | Repo for BenTsao [original name: HuaTuo (åé©¼)], Instruction-tuning Large Language Models with Chinese Medical Knowledge. æœ¬è‰ï¼ˆåŸåï¼šåé©¼ï¼‰æ¨¡å‹ä»“åº“ï¼ŒåŸºäºä¸­æ–‡åŒ»å­¦çŸ¥è¯†çš„å¤§è¯­è¨€æ¨¡å‹æŒ‡ä»¤å¾®è°ƒ | 2025-02-21T02:04:37Z |
| 77 | [sdk-python](https://github.com/strands-agents/sdk-python) | 4914 | 603 | Python | 275 | A model-driven approach to building AI agents in just a few lines of code. | 2026-01-20T22:41:28Z |
| 78 | [h2o-llmstudio](https://github.com/h2oai/h2o-llmstudio) | 4776 | 508 | Python | 42 | H2O LLM Studio - a framework and no-code GUI for fine-tuning LLMs. Documentation: https://docs.h2o.ai/h2o-llmstudio/ | 2026-01-19T17:47:31Z |
| 79 | [transformerlab-app](https://github.com/transformerlab/transformerlab-app) | 4743 | 498 | Python | 67 | Open Source Machine Learning Research Platform designed for frontier AI/ML workflows. Local, on-prem, or in the cloud. Open source. | 2026-01-20T22:43:09Z |
| 80 | [MedicalGPT](https://github.com/shibing624/MedicalGPT) | 4628 | 670 | Python | 53 | MedicalGPT: Training Your Own Medical GPT Model with ChatGPT Training Pipeline. è®­ç»ƒåŒ»ç–—å¤§æ¨¡å‹ï¼Œå®ç°äº†åŒ…æ‹¬å¢é‡é¢„è®­ç»ƒ(PT)ã€æœ‰ç›‘ç£å¾®è°ƒ(SFT)ã€RLHFã€DPOã€ORPOã€GRPOã€‚ | 2026-01-18T10:35:09Z |
| 81 | [obsidian-smart-connections](https://github.com/brianpetro/obsidian-smart-connections) | 4482 | 272 | JavaScript | 448 | Chat with your notes & see links to related content with AI embeddings. Use local models or 100+ via APIs like Claude, Gemini, ChatGPT & Llama 3 | 2026-01-17T23:08:25Z |
| 82 | [gpustack](https://github.com/gpustack/gpustack) | 4400 | 447 | Python | 402 | Performance-Optimized AI Inference on Your GPUs. Unlock it by selecting and tuning the optimal inference engine for your model. | 2026-01-21T01:39:39Z |
| 83 | [casibase](https://github.com/casibase/casibase) | 4396 | 523 | Go | 52 | âš¡ï¸AI Cloud OS: Open-source enterprise-level AI knowledge base and MCP (model-context-protocol)/A2A (agent-to-agent) management platform with admin UI, user management and Single-Sign-Onâš¡ï¸, supports ChatGPT, Claude, Llama, Ollama, HuggingFace, etc., chat bot demo: https://ai.casibase.com, admin UI demo: https://ai-admin.casibase.com | 2026-01-20T13:40:30Z |
| 84 | [tiny-universe](https://github.com/datawhalechina/tiny-universe) | 4366 | 434 | Jupyter Notebook | 9 | ã€Šå¤§æ¨¡å‹ç™½ç›’å­æ„å»ºæŒ‡å—ã€‹ï¼šä¸€ä¸ªå…¨æ‰‹æ“çš„Tiny-Universe | 2025-12-02T06:12:39Z |
| 85 | [GPT-4-LLM](https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM) | 4342 | 306 | HTML | 13 | Instruction Tuning with GPT-4 | 2023-06-11T13:40:30Z |
| 86 | [llama-stack-apps](https://github.com/llamastack/llama-stack-apps) | 4288 | 643 | None | 20 | Agentic components of the Llama Stack APIs | 2025-08-05T14:49:58Z |
| 87 | [llama_cloud_services](https://github.com/run-llama/llama_cloud_services) | 4229 | 469 | TypeScript | 334 | Knowledge Agents and Management in the Cloud | 2026-01-18T22:43:50Z |
| 88 | [g1](https://github.com/build-with-groq/g1) | 4218 | 367 | Python | 0 | g1: Using Llama-3.1 70b on Groq to create o1-like reasoning chains | 2025-12-30T22:28:50Z |
| 89 | [llama3-Chinese-chat](https://github.com/CrazyBoyM/llama3-Chinese-chat) | 4162 | 337 | Python | 30 | Llama3ã€Llama3.1 ä¸­æ–‡åè®­ç»ƒç‰ˆä»“åº“ - å¾®è°ƒã€é­”æ”¹ç‰ˆæœ¬æœ‰è¶£æƒé‡ & è®­ç»ƒã€æ¨ç†ã€è¯„æµ‹ã€éƒ¨ç½²æ•™ç¨‹è§†é¢‘ & æ–‡æ¡£ã€‚ | 2026-01-06T15:22:35Z |
| 90 | [llama-dl](https://github.com/shawwn/llama-dl) | 4146 | 409 | Shell | 9 | High-speed download of LLaMA, Facebook's 65B parameter GPT model | 2023-06-28T16:56:55Z |
| 91 | [Chinese-Vicuna](https://github.com/Facico/Chinese-Vicuna) | 4141 | 412 | C | 65 | Chinese-Vicuna: A Chinese Instruction-following LLaMA-based Model â€”â€” ä¸€ä¸ªä¸­æ–‡ä½èµ„æºçš„llama+loraæ–¹æ¡ˆï¼Œç»“æ„å‚è€ƒalpaca | 2025-04-18T02:41:35Z |
| 92 | [PurpleLlama](https://github.com/meta-llama/PurpleLlama) | 3984 | 689 | Python | 21 | Set of tools to assess and improve LLM security. | 2026-01-19T22:02:58Z |
| 93 | [llms-from-scratch-cn](https://github.com/datawhalechina/llms-from-scratch-cn) | 3919 | 533 | Jupyter Notebook | 13 | ä»…éœ€PythonåŸºç¡€ï¼Œä»0æ„å»ºå¤§è¯­è¨€æ¨¡å‹ï¼›ä»0é€æ­¥æ„å»ºGLM4\Llama3\RWKV6ï¼Œ æ·±å…¥ç†è§£å¤§æ¨¡å‹åŸç† | 2024-08-15T02:19:06Z |
| 94 | [LightLLM](https://github.com/ModelTC/LightLLM) | 3854 | 295 | Python | 81 | LightLLM is a Python-based LLM (Large Language Model) inference and serving framework, notable for its lightweight design, easy scalability, and high-speed performance. | 2026-01-21T04:10:39Z |
| 95 | [langroid](https://github.com/langroid/langroid) | 3847 | 351 | Python | 48 | Harness LLMs with Multi-Agent Programming | 2026-01-16T15:17:14Z |
| 96 | [zero_nlp](https://github.com/yuanzhoulvpi2017/zero_nlp) | 3761 | 447 | Jupyter Notebook | 102 | ä¸­æ–‡nlpè§£å†³æ–¹æ¡ˆ(å¤§æ¨¡å‹ã€æ•°æ®ã€æ¨¡å‹ã€è®­ç»ƒã€æ¨ç†)  | 2025-08-05T01:26:45Z |
| 97 | [lorax](https://github.com/predibase/lorax) | 3679 | 304 | Python | 150 | Multi-LoRA inference server that scales to 1000s of fine-tuned LLMs | 2025-05-21T17:40:25Z |
| 98 | [ClaraVerse](https://github.com/claraverse-space/ClaraVerse) | 3668 | 410 | TypeScript | 61 | ClaraVerse is a privacy-first, fully local AI workspace featuring a Local LLM chat powered by LLama.cpp, along with support for any provider, tool calling, agent building, Stable Diffusion, and n8n-style automation. It requires no backend or API keysâ€”just your stack and machine. | 2026-01-05T08:39:35Z |
| 99 | [shimmy](https://github.com/Michael-A-Kuykendall/shimmy) | 3542 | 263 | Rust | 23 | âš¡ Python-free Rust inference server â€” OpenAI-API compatible. GGUF + SafeTensors, hot model swap, auto-discovery, single binary. FREE now, FREE forever. | 2026-01-16T23:01:22Z |
| 100 | [higgsfield](https://github.com/higgsfield-ai/higgsfield) | 3528 | 587 | Jupyter Notebook | 2 | Fault-tolerant, highly scalable GPU orchestration, and a machine learning framework designed for training models with billions to trillions of parameters | 2024-05-25T17:43:07Z |

